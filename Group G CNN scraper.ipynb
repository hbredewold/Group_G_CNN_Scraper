{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "accepted-society",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "import csv\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.common.exceptions import StaleElementReferenceException\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd\n",
    "\n",
    "def scrape_cnn_articles(stop_date, search_term, start_page):\n",
    "    options = Options()\n",
    "    options.headless = False\n",
    "    driver = webdriver.Chrome(options=options)\n",
    "    results = []\n",
    "\n",
    "    stop_date_object = datetime.strptime(stop_date, '%b %d, %Y')\n",
    "\n",
    "    try:\n",
    "        driver.get(f'https://edition.cnn.com/search?q={search_term}&from=0&size=10&page={start_page}&sort=newest&types=article&section=')\n",
    "\n",
    "        while True:\n",
    "            WebDriverWait(driver, 10).until(\n",
    "                EC.presence_of_all_elements_located((By.CLASS_NAME, 'card'))\n",
    "            )\n",
    "\n",
    "            soup = BeautifulSoup(driver.page_source, 'html.parser')\n",
    "            articles = soup.find_all('div', class_='card')\n",
    "\n",
    "            for article in articles:\n",
    "                date_element = article.find('div', class_='container__date')\n",
    "                date_string = date_element.get_text(strip=True) if date_element else 'Date not available'\n",
    "\n",
    "                date_object = datetime.strptime(date_string, '%b %d, %Y')\n",
    "\n",
    "                headline_element = article.find('span', class_='container__headline-text')\n",
    "                headline = headline_element.get_text(strip=True) if headline_element else 'Headline not available'\n",
    "\n",
    "                link_element = article.find('a')\n",
    "                link = link_element['href'] if link_element else 'Link not available'\n",
    "\n",
    "                results.append({\n",
    "                    'Headline': headline,\n",
    "                    'Link': link,\n",
    "                    'Date': date_object  \n",
    "                })\n",
    "\n",
    "                if date_object < stop_date_object:\n",
    "                    print(f'Stopping scraping as an article with date {date_string} has been reached.')\n",
    "                \n",
    "                    with open(f'{search_term}_scraped_data.csv', 'w', newline='', encoding='utf-8') as csv_file:\n",
    "                        fieldnames = ['Headline', 'Link', 'Date']\n",
    "                        writer = csv.DictWriter(csv_file, fieldnames=fieldnames)\n",
    "                        writer.writeheader()\n",
    "                        for result in results:\n",
    "                            writer.writerow(result)\n",
    "                    print(f'Scraped data has been saved to {search_term}_scraped_data.csv')\n",
    "                    return results\n",
    "\n",
    "            try:\n",
    "                next_page_button = WebDriverWait(driver, 10).until(\n",
    "                    EC.presence_of_element_located((By.CLASS_NAME, 'pagination-arrow-right'))\n",
    "                )\n",
    "\n",
    "                driver.execute_script(\"arguments[0].scrollIntoView(true);\", next_page_button)\n",
    "                \n",
    "                time.sleep(7)\n",
    "                \n",
    "                next_page_button.click()\n",
    "\n",
    "            except StaleElementReferenceException:\n",
    "                print('Stale element reference. Retrying to find the next page button.')\n",
    "                continue\n",
    "\n",
    "    finally:\n",
    "        driver.quit()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "hungarian-cabin",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping scraping as an article with date Oct 06, 2023 has been reached.\n",
      "Scraped data has been saved to Israel_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Israel\n",
    "scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Israel\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "neural-delta",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stopping scraping as an article with date Oct 04, 2023 has been reached.\n",
      "Scraped data has been saved to Palestine_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Palestine\n",
    "scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Palestine\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "digital-austria",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stopping scraping as an article with date Aug 22, 2023 has been reached.\n",
      "Scraped data has been saved to Hamas_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Hamas\n",
    "scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Hamas\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "piano-greece",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stopping scraping as an article with date Oct 06, 2023 has been reached.\n",
      "Scraped data has been saved to Gaza_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Gaza\n",
    "scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"Gaza\", \"1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "id": "transsexual-thumbnail",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping scraping as an article with date Oct 06, 2023 has been reached.\n",
      "Scraped data has been saved to IDF_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#IDF\n",
    "scraped_articles = scrape_cnn_articles('Oct 07, 2023', \"IDF\", \"1\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "refined-lying",
   "metadata": {},
   "source": [
    "Combining CSV files and filtering on date"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "id": "finished-grain",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['Gaza_scraped_data.csv', 'Hamas_scraped_data.csv', 'Israel_scraped_data.csv', 'Palestine_scraped_data.csv', 'IDF_scraped_data.csv'] \n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "combined_df.to_csv('israel_palestine_conflict.csv', index=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "atmospheric-section",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('israel_palestine_conflict.csv')\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "start_date = '2023-10-07'\n",
    "end_date = '2023-12-07'\n",
    "filtered_df = df.loc[start_date:end_date]\n",
    "\n",
    "filtered_df.reset_index(inplace=True)\n",
    "\n",
    "filtered_df.to_csv('israel_palestine_conflict.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "heavy-local",
   "metadata": {},
   "source": [
    "RUSSO UKRAINIAN WAR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "applied-macro",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stopping scraping as an article with date Feb 23, 2022 has been reached.\n",
      "Scraped data has been saved to Ukraine_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Ukraine\n",
    "scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Ukraine\", \"207\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "impossible-methodology",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping scraping as an article with date Feb 23, 2022 has been reached.\n",
      "Scraped data has been saved to Russia_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Russia\n",
    "scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Russia\", \"176\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "id": "western-torture",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stale element reference. Retrying to find the next page button.\n",
      "Stopping scraping as an article with date Feb 23, 2022 has been reached.\n",
      "Scraped data has been saved to Putin_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Putin\n",
    "scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Putin\", \"181\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "reserved-profile",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Stopping scraping as an article with date Feb 19, 2022 has been reached.\n",
      "Scraped data has been saved to Zelensky_scraped_data.csv\n"
     ]
    }
   ],
   "source": [
    "#Zelensky\n",
    "scraped_articles = scrape_cnn_articles('Feb 24, 2022', \"Zelensky\", \"14\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "usual-inclusion",
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_files = ['Russia_scraped_data.csv', 'Zelensky_scraped_data.csv', 'Ukraine_scraped_data.csv', 'Putin_scraped_data.csv'] \n",
    "\n",
    "dfs = []\n",
    "\n",
    "for file in csv_files:\n",
    "    df = pd.read_csv(file)\n",
    "    dfs.append(df)\n",
    "\n",
    "combined_df = pd.concat(dfs, ignore_index=True)\n",
    "combined_df.drop_duplicates(inplace=True)\n",
    "combined_df.to_csv('russia_ukraine_conflict.csv', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "average-ticket",
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('russia_ukraine_conflict.csv')\n",
    "\n",
    "df['Date'] = pd.to_datetime(df['Date'])\n",
    "df.set_index('Date', inplace=True)\n",
    "\n",
    "start_date = '2022-02-24'\n",
    "end_date = '2022-04-24'\n",
    "filtered_df = df.loc[start_date:end_date]\n",
    "\n",
    "filtered_df.reset_index(inplace=True)\n",
    "\n",
    "filtered_df.to_csv('russia_ukraine_conflict.csv', index=False)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
